{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson problem (1D/2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuqi.problem import BayesianProblem\n",
    "from cuqi.distribution import Gaussian\n",
    "from cuqipy_fenics.utilities import ExpressionFromCallable\n",
    "from cuqipy_fenics.testproblem import FEniCSPoisson2D, FEniCSDiffusion1D\n",
    "import numpy as np\n",
    "import cuqi\n",
    "import cuqipy_fenics\n",
    "import dolfin as dl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print CUQIpy and CUQIpy-FEniCS versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cuqi.__version__)\n",
    "print(cuqipy_fenics.__version__)\n",
    "print(cuqipy_fenics.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_dim = 1 # choice of physical dimension\n",
    "prior_type = 'TV'#'Gaussian' #'TV' #'Gaussian' # 'TV'\n",
    "enable_FD = True\n",
    "sampler_choice = \"MH\" #\"NUTS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 10 # domain length\n",
    "# f is sum of 3 exponentials at 1/4*endpoint and 1/2*endpoint and 3/4*endpoint\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(-100*(x-1/4*endpoint)**2) + np.exp(-100*(x-1/2*endpoint)**2) + np.exp(-100*(x-3/4*endpoint)**2)\n",
    "\n",
    "#plot f\n",
    "x = np.linspace(0, endpoint, 100)\n",
    "plt.plot(x, f(x))\n",
    "\n",
    "\n",
    "f_expr = ExpressionFromCallable(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if physical_dim == 2:\n",
    "    A = FEniCSPoisson2D(dim=(16,16), field_type=None, mapping='exponential', bc_types=['Dirichlet', 'Neumann', 'Dirichlet', 'Neumann']).model\n",
    "elif physical_dim == 1:\n",
    "\n",
    "    A = FEniCSDiffusion1D(dim=20, right_bc=0, f=f_expr, endpoint=endpoint).model # note source term is zero for the 1D case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_domain = A.domain_geometry\n",
    "G_range = A.range_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMPrior class\n",
    "class SMPrior:\n",
    "    def __init__(self, ginv, corrlength, var, mean, covariancetype=None):\n",
    "        self.corrlength = corrlength\n",
    "        self.mean = mean\n",
    "        self.c = 1e-9  # default value\n",
    "        if covariancetype is not None:\n",
    "            self.covariancetype = covariancetype\n",
    "        else:\n",
    "            self.covariancetype = 'Squared Distance'  # default\n",
    "        self.compute_L(ginv, corrlength, var)\n",
    "\n",
    "    def compute_L(self, g, corrlength, var):\n",
    "        ng = g.shape[0]\n",
    "        a = var - self.c\n",
    "        b = np.sqrt(-corrlength**2 / (2 * np.log(0.01)))\n",
    "        Gamma_pr = np.zeros((ng, ng))\n",
    "\n",
    "        for ii in range(ng):\n",
    "            for jj in range(ii, ng):\n",
    "                dist_ij = np.linalg.norm(g[ii, :] - g[jj, :])\n",
    "                if self.covariancetype == 'Squared Distance':\n",
    "                    gamma_ij = a * np.exp(-dist_ij**2 / (2 * b**2))\n",
    "                elif self.covariancetype == 'Ornstein-Uhlenbeck':\n",
    "                    gamma_ij = a * np.exp(-dist_ij / corrlength)\n",
    "                else:\n",
    "                    raise ValueError('Unrecognized prior covariance type')\n",
    "                if ii == jj:\n",
    "                    gamma_ij = gamma_ij + self.c\n",
    "                Gamma_pr[ii, jj] = gamma_ij\n",
    "                Gamma_pr[jj, ii] = gamma_ij\n",
    "        \n",
    "        self.cov = Gamma_pr\n",
    "        self.L = np.linalg.cholesky(np.linalg.inv(Gamma_pr)).T\n",
    "\n",
    "    def draw_samples(self, nsamples):\n",
    "        samples = self.mean + np.linalg.solve(self.L, np.random.randn(self.L.shape[0], nsamples))\n",
    "        return samples\n",
    "\n",
    "    def eval_fun(self, args):\n",
    "        sigma = args[0]\n",
    "        res = 0.5 * np.linalg.norm(self.L @ (sigma - self.mean))**2\n",
    "        return res\n",
    "    \n",
    "    def evaluate_target_external(self, x, compute_grad=False):\n",
    "        x = x.reshape((-1,1))\n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        # print(\"self.mean.shape: \", self.mean.shape)\n",
    "        if compute_grad:\n",
    "            grad = self.L.T @ self.L @ (x - self.mean)\n",
    "        else:\n",
    "            grad = None\n",
    "        \n",
    "        return self.eval_fun(x), grad\n",
    "        \n",
    "\n",
    "    def compute_hess_and_grad(self, args, nparam):\n",
    "        sigma = args[0]\n",
    "        Hess = self.L.T @ self.L\n",
    "        grad = Hess @ (sigma - self.mean)\n",
    "\n",
    "        if nparam > len(sigma):\n",
    "            Hess = np.block([[Hess, np.zeros((len(sigma), nparam - len(sigma)))],\n",
    "                             [np.zeros((nparam - len(sigma), len(sigma))), np.zeros((nparam - len(sigma), nparam - len(sigma)))]])\n",
    "            grad = np.concatenate([grad, np.zeros(nparam - len(sigma))])\n",
    "\n",
    "\n",
    "        return Hess, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class MyTV:\n",
    "#    def __init__(self, q0fun, mesh, delta,**kwargs):\n",
    "#        #self.qfun = project(qFunction(phi,q1,q2),V1)\n",
    "#\n",
    "#        self.V1 = FunctionSpace(mesh,'CG',1)\n",
    "#        self.V02 = VectorFunctionSpace(mesh,'DG',0)\n",
    "#\n",
    "#        self.q0fun = q0fun\n",
    "#        self.q0grad = project(grad(self.q0fun),self.V02)\n",
    "#        self.q0_denom = Denom(self.q0grad,delta)\n",
    "#\n",
    "#        # operator\n",
    "#        self.p_trial = TrialFunction(self.V1)\n",
    "#        self.p_test = TestFunction(self.V1)\n",
    "#\n",
    "#        #self.L_op = assemble(ufl.inner(self.p_trial, self.p_test)*dx)\n",
    "#        #self.TV_op = assemble(self.q_denom*ufl.inner(grad(self.p_trial),grad(self.p_test))*dx)\n",
    "#        self.TV_op = assemble((self.q0_denom*inner(grad(self.p_trial),grad(self.p_test)))*dx)\n",
    "#\n",
    "#        self.delta = delta\n",
    "#\n",
    "#    def eval_TV(self,qfun):\n",
    "#        self.update_op(qfun)\n",
    "#        return np.dot(self.TV_op * qfun.vector(),qfun.vector())\n",
    "#\n",
    "#    def eval_grad(self,qfun):\n",
    "#        self.update_op(qfun)\n",
    "#        return 2*(self.TV_op * qfun.vector())#[idx2]\n",
    "#    \n",
    "#    def update_op(self,q0fun):\n",
    "#        self.q0fun = q0fun\n",
    "#        self.q0grad = project(grad(self.q0fun),self.V02)\n",
    "#        self.q0_denom = Denom(self.q0grad,self.delta)\n",
    "#        self.TV_op = assemble((self.q0_denom*inner(grad(self.p_trial),grad(self.p_test)))*dx) \n",
    "#\n",
    "\n",
    "class TV_reg:\n",
    "    def __init__(self, V, beta, weight):\n",
    "        self.beta    = dl.Constant(beta)\n",
    "        self.m_tilde  = dl.TestFunction(V)\n",
    "        self.m_hat = dl.TrialFunction(V)\n",
    "        self.weight = weight\n",
    "        \n",
    "    def cost_reg(self, m):\n",
    "        return self.weight*dl.assemble(dl.sqrt( dl.inner(dl.grad(m), dl.grad(m)) + self.beta)*dl.dx)\n",
    "\n",
    "    \n",
    "    def grad_reg(self, m):  \n",
    "        print(\"grad\", dl.grad)      \n",
    "        TVm = dl.sqrt( dl.inner(dl.grad(m), dl.grad(m)) + self.beta)\n",
    "        grad_val = dl.assemble(dl.Constant(1.)/TVm*dl.inner(dl.grad(m), dl.grad(self.m_tilde))*dl.dx)\n",
    "        return self.weight*grad_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = G_domain.function_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_reg = TV_reg(H, 1e-3, weight=1)\n",
    "\n",
    "def eval_density(x):\n",
    "    # convert from numpy array to dolfin function\n",
    "    x_fun = dl.Function(H)\n",
    "    x_fun.vector()[:] = x\n",
    "    return tv_reg.cost_reg(x_fun)\n",
    "\n",
    "def eval_grad_density(x):\n",
    "    # convert from numpy array to dolfin function\n",
    "    x_fun = dl.Function(H)\n",
    "    x_fun.vector()[:] = x\n",
    "    grad_val = tv_reg.grad_reg(x_fun).get_local()\n",
    "    return grad_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create correlation matrix for prior x\n",
    "\n",
    "\n",
    "\n",
    "v2d = dl.vertex_to_dof_map(H)\n",
    "d2v = dl.dof_to_vertex_map(H)\n",
    "\n",
    "mesh = G_domain.mesh \n",
    "\n",
    "\n",
    "mean_sigma = np.zeros((H.dim(), 1)) #linearization point\n",
    "corrlength =  0.2* endpoint\n",
    "var_sigma = 0.05 ** 2   #prior variance\n",
    "\n",
    "smprior = SMPrior(mesh.coordinates()[d2v], corrlength, var_sigma, mean_sigma)#, covariancetype='Ornstein-Uhlenbeck')\n",
    "\n",
    "\n",
    "sample = smprior.draw_samples(1)\n",
    "fun = dl.Function(H)\n",
    "fun.vector().set_local(sample)\n",
    "\n",
    "im = dl.plot(fun)\n",
    "if physical_dim == 2:\n",
    "    plt.colorbar(im)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the covariance matrix \n",
    "plt.figure()\n",
    "im = plt.imshow(smprior.cov)\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prior_type == 'Gaussian':\n",
    "    cov_const = 1 #100\n",
    "    x = Gaussian(np.zeros(G_domain.par_dim), cov=cov_const*smprior.cov, geometry=G_domain)\n",
    "elif prior_type == 'TV':\n",
    "    # CUQIpy user defined distribution\n",
    "    x = cuqi.distribution.UserDefinedDistribution(logpdf_func=eval_density,\n",
    "                                              gradient_func=eval_grad_density,\n",
    "                                              dim=H.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prior_type == 'Gaussian':\n",
    "    x_true = x.sample()\n",
    "elif prior_type == 'TV':\n",
    "    fun_x_true_expr = dl.Expression('x[0] > 5 ? 0 : -0.5', degree=1)\n",
    "    x_true_fun = dl.interpolate(fun_x_true_expr, H)\n",
    "    x_true = cuqi.array.CUQIarray(x_true_fun.vector().get_local(), geometry=G_domain)\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Unrecognized prior type')\n",
    "im = x_true.plot()\n",
    "if physical_dim == 2:\n",
    "    plt.colorbar(im[0])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell to compute s_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.01\n",
    "y_true = A(x_true)\n",
    "s_noise = 1.0/np.sqrt(G_domain.par_dim)* noise_level*np.linalg.norm(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Gaussian(A(x), s_noise**2, geometry=G_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = y(x=x_true).sample()\n",
    "y_obs.plot()\n",
    "y_true.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = BayesianProblem(y, x).set_data(y=y_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map point\n",
    "if enable_FD:\n",
    "    BP.posterior.enable_FD() \n",
    "else:\n",
    "    BP.posterior.disable_FD()\n",
    "map_x = BP.MAP()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot map predicted data\n",
    "\n",
    "y_obs.plot(label='y_obs')\n",
    "A(map_x).plot(label='A(x_map)')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_x.plot()\n",
    "dl.plot(x_true.funvals)#.plot('--')\n",
    "plt.legend(['MAP', 'True'])\n",
    "#plt.ylim(-1.5, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior_samples = BP.UQ(Ns=3000, Nb=2, percent=97)\n",
    "posterior = BP.posterior()\n",
    "#sampler = cuqi.sampler.NUTS(posterior, max_depth=4, x0=np.zeros(G_domain.par_dim)+.001)\n",
    "#sampler = cuqi.sampler.ULA(posterior, x0=np.zeros(G_domain.par_dim)+.001, scale=0.00000005)\n",
    "# np.zeros(G_domain.par_dim)+.001\n",
    "\n",
    "initial_point = np.zeros(G_domain.par_dim) # x_true.to_numpy()\n",
    "#initial_point = 0.5*map_x.to_numpy()\n",
    "\n",
    "#sampler = cuqi.experimental.mcmc.PCN(posterior, initial_point=initial_point, scale=0.05)#, max_depth=10, scale=0.005)\n",
    "\n",
    "if sampler_choice == \"NUTS\":\n",
    "    sampler = cuqi.experimental.mcmc.NUTS(posterior, initial_point=initial_point, max_depth=5, step_size=1e-3)\n",
    "    Ns = 400\n",
    "    Nb = 20 #20\n",
    "elif sampler_choice == \"MALA\":\n",
    "    sampler = cuqi.experimental.mcmc.MALA(posterior, initial_point=initial_point, scale=2.1e-7)\n",
    "    Ns = 1000\n",
    "    Nb = 20\n",
    "\n",
    "elif sampler_choice == \"ULA\":\n",
    "    sampler = cuqi.experimental.mcmc.ULA(posterior, initial_point=initial_point, scale=2.1e-7)\n",
    "    Ns = 100\n",
    "    Nb = 20\n",
    "\n",
    "elif sampler_choice == \"MH\":\n",
    "    sampler = cuqi.experimental.mcmc.MH(posterior, initial_point=initial_point, scale=2.1e-5)\n",
    "    Ns = 1000\n",
    "    Nb = 20\n",
    "\n",
    "\n",
    "_ = sampler.warmup(Nb)\n",
    "_ = sampler.sample(Ns)\n",
    "\n",
    "\n",
    "#posterior_samples = sampler.sample_adapt(100, Nb=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_extra = 80\n",
    "posterior_samples = sampler.get_samples().burnthin(Nb+Nb_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(sampler.scale)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.plot(sampler.num_tree_node_list)\n",
    "    plt.figure()\n",
    "    plt.semilogy(sampler.epsilon_list)\n",
    "    plt.semilogy(sampler.epsilon_bar_list)\n",
    "    print(np.max(sampler.epsilon_list))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler.scale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code cell for generating Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up matplotlib\n",
    "SMALL_SIZE = 7\n",
    "MEDIUM_SIZE = 8\n",
    "BIGGER_SIZE = 9\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Use latex package\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "\n",
    "# Data directory\n",
    "fig_dir = './figs/'\n",
    "\n",
    "# Figure file\n",
    "fig_dir = fig_dir \n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "# Figure version\n",
    "version = 'v8'\n",
    "\n",
    "# Figure file\n",
    "fig_file = fig_dir + 'paper_figure1_'+version+'.pdf'\n",
    "\n",
    "# Create the figure\n",
    "cm_to_in = 1/2.54\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3,\n",
    "                        figsize=(17.8*cm_to_in, 9.8*cm_to_in),\n",
    "                        layout=\"constrained\")\n",
    "\n",
    "# Define the colors to be used in the plots\n",
    "colors = ['C0', 'green', 'purple', 'k', 'gray']\n",
    "\n",
    "# (a)\n",
    "plt.sca(axs[0,0])\n",
    "im = x_true.plot(subplots=False)#, vmin=-0.2, vmax=0.5, mode='color')\n",
    "\n",
    "if physical_dim == 2: \n",
    "    inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "    fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "\n",
    "#plt.gca().set_xlim(0, 1)\n",
    "plt.gca().set_title('(a) Exact solution')\n",
    "plt.ylabel('$\\\\xi^2$')\n",
    "plt.gca().yaxis.labelpad = -5\n",
    "plt.xlabel('$\\\\xi^1$')\n",
    "plt.gca().xaxis.labelpad = -5\n",
    "\n",
    "# (b)\n",
    "plt.sca(axs[0,1])\n",
    "im = y_true.plot(subplots=False)\n",
    "\n",
    "if physical_dim == 2:\n",
    "    inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "    fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "    plt.ylabel('$\\\\xi^2$')\n",
    "    plt.gca().yaxis.labelpad = -5\n",
    "    plt.gca().set_title('(b) Exact data')\n",
    "else:\n",
    "    samples_mean = cuqi.array.CUQIarray(posterior_samples.mean(), geometry=G_domain)\n",
    "    A(samples_mean).plot(subplots=False)\n",
    "    plt.gca().set_title('(b) Exact and predicted data')\n",
    "plt.xlabel('$\\\\xi^1$')\n",
    "plt.gca().xaxis.labelpad = -5\n",
    "\n",
    "\n",
    "# (c)\n",
    "plt.sca(axs[0,2])\n",
    "im = y_obs.plot(subplots=False)\n",
    "if physical_dim == 2:\n",
    "    inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "    fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "    plt.ylabel('$\\\\xi^2$')\n",
    "    plt.gca().yaxis.labelpad = -5\n",
    "plt.xlabel('$\\\\xi^1$')\n",
    "plt.gca().xaxis.labelpad = -5\n",
    "plt.gca().set_title('(c) Noisy data')\n",
    "\n",
    "# (d)\n",
    "plt.sca(axs[1,0])\n",
    "im = posterior_samples.plot_mean(\n",
    "    subplots=False)#, vmin=-0.2, vmax=0.5, mode='color')\n",
    "if physical_dim == 2:\n",
    "    inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "    fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.ylabel('$\\\\xi^2$')\n",
    "    plt.gca().yaxis.labelpad = -5\n",
    "\n",
    "#plt.gca().set_xlim(0, 1)\n",
    "plt.xlabel('$\\\\xi^1$')\n",
    "plt.gca().xaxis.labelpad = -5\n",
    "plt.gca().set_title('(d) Posterior mean')\n",
    "\n",
    "# (e)\n",
    "plt.sca(axs[1,1])\n",
    "im = posterior_samples.funvals.vector.plot_variance(subplots=False)\n",
    "\n",
    "if physical_dim == 2:\n",
    "    inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "    cb = fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "    cb.locator = ticker.MaxNLocator(nbins=4)\n",
    "    plt.ylabel('$\\\\xi^2$')\n",
    "    plt.gca().yaxis.labelpad = -5\n",
    "plt.xlabel('$\\\\xi^1$')\n",
    "plt.gca().xaxis.labelpad = -5\n",
    "plt.gca().set_title('(e) Posterior variance')\n",
    "\n",
    "# (f)\n",
    "plt.sca(axs[1,2])\n",
    "lci = posterior_samples.plot_ci(\n",
    "    97, exact=x_true, plot_par=True, markersize=SMALL_SIZE-3)\n",
    "lci[0].set_label(\"Mean\")\n",
    "lci[1].set_label(\"Exact\")\n",
    "lci[2].set_label(\"$97\\\\%$ CI\")\n",
    "#plt.ylim(-5, 3)\n",
    "plt.legend(ncols=2) \n",
    "plt.ylabel(r'$\\bm{x}_i$')\n",
    "plt.gca().yaxis.labelpad = -5\n",
    "plt.gca().yaxis.set_label_coords( -0.06, 0.5)\n",
    "plt.xlabel('$i$')\n",
    "plt.gca().xaxis.labelpad = -5\n",
    "plt.gca().set_title('(f) Posterior CI')\n",
    "n_ticks = 8\n",
    "num_var = posterior_samples.geometry.par_dim\n",
    "tick_ids = np.linspace(0, num_var-1, n_ticks, dtype=int)\n",
    "plt.xticks(tick_ids, tick_ids)\n",
    "# switch legend off\n",
    "plt.gca().legend().set_visible(False)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(fig_file, bbox_inches='tight', pad_inches=0.01, dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_list = posterior_samples.compute_ess()\n",
    "print(ess_list)\n",
    "print(np.min(ess_list))\n",
    "print(np.max(ess_list))\n",
    "print(np.mean(ess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [x] 1D case \n",
    "# - [ ] DG0\n",
    "# - [ ] TV with non-MY gradient and with NUTS \n",
    "# - [x] verify the gradient of the posterior\n",
    "# - [x] PCN seems to work (for both 1D and 2D cases)\n",
    "# - [x] Start from x0=the true parameter to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify gradient  (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import check_grad\n",
    "from scipy.optimize import check_grad\n",
    "from cuqi.utilities import approx_gradient\n",
    "\n",
    "np.random.seed(3)\n",
    "# random direction y\n",
    "y0 = np.ones(G_range.par_dim) # np.random.randn(G_range.par_dim)\n",
    "y0[0] = 0\n",
    "y0[-1] = 0\n",
    "V = G_range.function_space\n",
    "# corresponding fenics function\n",
    "y0_fun = dl.Function(V)\n",
    "y0_fun.vector()[:] = y0\n",
    "\n",
    "# objective function\n",
    "def f(x):\n",
    "    return A(x).T@ y0.reshape(-1,1)\n",
    "    #return A(x).vector().get_local().T@ y0.reshape(-1,1)\n",
    "\n",
    "# objective function gradient\n",
    "def fprime(x):\n",
    "    return A.gradient(y0, x)\n",
    "\n",
    "# random input x (the point which gradient is calculated with respect to)\n",
    "x0 = np.random.randn(G_domain.par_dim)\n",
    "\n",
    "# assert that the gradient is correct\n",
    "print(check_grad(f, fprime, x0))\n",
    "\n",
    "plt.plot(fprime(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(f, x_true, 1e-6), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify gradient  (posterior)\n",
    "\n",
    "plt.plot(posterior.gradient(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(posterior.logd, x_true, 1e-8), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the gradient of the prior\n",
    "\n",
    "plt.plot(x.gradient(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(x.logd, x_true, 1e-8), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the gradient of the likelihood\n",
    "\n",
    "plt.plot(posterior.likelihood.gradient(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(posterior.likelihood.logd, x_true, 1e-10), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 3,
  "vscode": {
   "interpreter": {
    "hash": "f83c72a7c5d885a4a7f43561cb77434137f6f5cf21a7418d4732e18616218db3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
