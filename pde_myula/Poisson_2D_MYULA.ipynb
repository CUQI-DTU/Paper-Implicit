{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson problem (1D/2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from cuqi.problem import BayesianProblem\n",
    "from cuqi.distribution import Gaussian\n",
    "from cuqipy_fenics.utilities import ExpressionFromCallable\n",
    "from cuqipy_fenics.testproblem import FEniCSPoisson2D, FEniCSDiffusion1D\n",
    "from cuqi.experimental.mcmc import MH, NUTS, MALA, ULA, MYULA\n",
    "from cuqi.implicitprior import RestorationPrior, MoreauYoshidaPrior\n",
    "import numpy as np\n",
    "import cuqi\n",
    "import cuqipy_fenics\n",
    "import dolfin as dl\n",
    "import matplotlib.pyplot as plt\n",
    "# import check_grad\n",
    "from scipy.optimize import check_grad\n",
    "from cuqi.utilities import approx_gradient\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "import os\n",
    "\n",
    "# set logging level of dl\n",
    "dl.set_log_level(dl.LogLevel.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuqipy_fenics.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print CUQIpy and CUQIpy-FEniCS versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cuqi.__version__)\n",
    "print(cuqipy_fenics.__version__)\n",
    "print(cuqipy_fenics.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read command line arguments\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Run MCMC for a given problem')\n",
    "parser.add_argument('--restoration_strength_factor', type=float, default=None, help='restoration strength factor for the TV prior')\n",
    "parser.add_argument('--par_dim', type=int, default=None, help='Dimension of the parameter space')\n",
    "\n",
    "args = parser.parse_args(os.environ['NB_ARGS'].split())\n",
    "#args = parser.parse_args(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_type = 'diffusion_2D'  #'convolution' #'convolution' #'diffusion' # 'identity' # choice of model type\n",
    "\n",
    "enable_FD = False\n",
    "#sampler_choice = \"NUTS\" #\"MALA\" #\"NUTS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter set up\n",
    "if model_type == 'convolution':\n",
    "    np.random.seed(0)\n",
    "    sampler_choice = \"NUTS\"\n",
    "    TV_weight = 1.0e2\n",
    "    TV_beta = 1e-4\n",
    "    plot_par = False\n",
    "    Ns = 1\n",
    "    Nb = 500\n",
    "    max_depth = 5\n",
    "    step_size = None\n",
    "    remove_burnin = 0\n",
    "    apply_grid_search=False\n",
    "    # initial point was zero\n",
    "\n",
    "    # these variables are not used in the deconvolution case\n",
    "    source_coeff = 5\n",
    "    sample_prior = False\n",
    "    prior_type = 'TV'#'Gaussian' #'TV' #'Gaussian' # 'TV'\n",
    "    nx = 40 if args.par_dim is None else args.par_dim\n",
    "\n",
    "if model_type == 'diffusion':\n",
    "    np.random.seed(0)\n",
    "    sampler_choice = \"myULA\"\n",
    "    TV_weight = 50 #40 #80 #40 #60\n",
    "    TV_beta = 1e-7\n",
    "    plot_par = True\n",
    "    Ns = 1000 #1000\n",
    "    Nb = 10 #20000\n",
    "    max_depth = 7\n",
    "    step_size = None\n",
    "    remove_burnin = 200 #0#int(Nb/2) #15000\n",
    "    apply_grid_search=False\n",
    "    signal_type = 'square'\n",
    "    set_x0_map_tobe_true = False\n",
    "    run_scipy_with_callback = False\n",
    "    noise_level = 0.01\n",
    "    source_coeff = 1\n",
    "    physical_dim = 1 # choice of physical dimension\n",
    "    sample_prior = False\n",
    "    prior_type = 'TV_denoiser'#'Gaussian' #'TV' #'Gaussian' # 'TV'\n",
    "    restoration_strength_factor = 0.01 if args.restoration_strength_factor is None else args.restoration_strength_factor\n",
    "    nx = 40 if args.par_dim is None else args.par_dim\n",
    "\n",
    "\n",
    "if model_type == 'diffusion_2D':\n",
    "    np.random.seed(0)\n",
    "    sampler_choice = \"myULA\"\n",
    "    TV_weight = 60 #35 #40 #80 #40 #60\n",
    "    TV_beta = 1e-6 #1e-7\n",
    "    plot_par = True\n",
    "    Ns = int(50) #5*20000 #1000\n",
    "    Nt= 2\n",
    "    Nb = 1 #20000\n",
    "    max_depth = 7\n",
    "    step_size = 0.005\n",
    "    remove_burnin = 10  #200 # 3000 #0#int(Nb/2) #15000\n",
    "    apply_grid_search=False\n",
    "    signal_type = 'square'\n",
    "    set_x0_map_tobe_true = False\n",
    "    run_scipy_with_callback = False\n",
    "    noise_level = 0.01\n",
    "    source_coeff = 1\n",
    "    physical_dim = 2 # choice of physical dimension\n",
    "    sample_prior = False\n",
    "    prior_type = 'TV_denoiser'#'Gaussian' #'TV' #'Gaussian' # 'TV'\n",
    "    restoration_strength_factor = 0.01 if args.restoration_strength_factor is None else args.restoration_strength_factor\n",
    "    nx = 16 if args.par_dim is None else int(np.sqrt(args.par_dim))\n",
    "    sample_batches = True\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_tag = f\"_nx_{nx}_rest_str_{restoration_strength_factor}_Ns_{Ns}\"\n",
    "print(expr_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_type == 'diffusion':\n",
    "    endpoint = 10 # domain length\n",
    "    # f is sum of 3 exponentials at 1/4*endpoint and 1/2*endpoint and 3/4*endpoint\n",
    "    \n",
    "    def f(x):\n",
    "        return np.exp(-source_coeff*(x-1/4*endpoint)**2) + np.exp(-source_coeff*(x-1/2*endpoint)**2) + np.exp(-source_coeff*(x-3/4*endpoint)**2)\n",
    "        #return np.ones(len(x))\n",
    "    \n",
    "    #plot f\n",
    "    x_grid = np.linspace(0, endpoint, 100)\n",
    "    plt.plot(x_grid, f(x_grid))\n",
    "    \n",
    "    \n",
    "    f_expr = ExpressionFromCallable(f)\n",
    "elif model_type == 'diffusion_2D':\n",
    "    f_expr = dl.Constant(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'diffusion_2D':\n",
    "    \n",
    "    A = FEniCSPoisson2D(dim=(nx,nx), field_type=None, mapping='exponential', bc_types=['Dirichlet', 'Dirichlet', 'Dirichlet', 'Dirichlet']).model\n",
    "elif model_type == 'diffusion':\n",
    "        A = FEniCSDiffusion1D(dim=nx, right_bc=0, f=f_expr, endpoint=endpoint).model # note source term is zero for the 1D case\n",
    "\n",
    "elif model_type == 'identity':\n",
    "    A = cuqi.model.LinearModel(np.eye(nx))\n",
    "\n",
    "elif model_type == 'convolution':\n",
    "    A = cuqi.testproblem.Deconvolution1D(dim=nx, PSF_param=2, PSF_size=nx).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot with one row and 4 columns\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 3))\n",
    "\n",
    "plt.sca(axs[0])\n",
    "# sin cos fenics expression\n",
    "f_expr_sin_cos = dl.Expression('sin(2*pi*x[0])*cos(2*pi*x[1])', degree=2)\n",
    "f_sin_cos = dl.interpolate(f_expr_sin_cos, A.domain_geometry.function_space)\n",
    "dl.plot(f_sin_cos)\n",
    "plt.title('original')\n",
    "\n",
    "plt.sca(axs[1])\n",
    "x_grid = f_sin_cos.compute_vertex_values().reshape((nx+1,nx+1))\n",
    "plt.imshow(x_grid)\n",
    "plt.title('on grid (clean)')\n",
    "\n",
    "# add noise to x_grid\n",
    "x_grid += np.random.normal(0, 0.1, x_grid.shape)\n",
    "plt.sca(axs[2])\n",
    "plt.imshow(x_grid)\n",
    "plt.title('on grid (noisy)')\n",
    "\n",
    "x_grid_tv = denoise_tv_chambolle(x_grid, weight=0.1, max_num_iter=100)\n",
    "plt.sca(axs[3])\n",
    "plt.imshow(x_grid_tv)\n",
    "plt.title('on grid (denoised)')\n",
    "\n",
    "# go back from x_grid to fenics function\n",
    "fun_from_x_grid = dl.Function(A.domain_geometry.function_space)\n",
    "\n",
    "#TODO: why d2v not v2d?\n",
    "plt.figure()\n",
    "v2d = dl.vertex_to_dof_map(A.domain_geometry.function_space)\n",
    "d2v = dl.dof_to_vertex_map(A.domain_geometry.function_space)\n",
    "fun_from_x_grid.vector()[:] = x_grid_tv.flatten()[d2v]\n",
    "dl.plot(fun_from_x_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_domain = A.domain_geometry\n",
    "G_range = A.range_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H_DG = A.domain_geometry.function_space\n",
    "#updated_domain_geometry = cuqipy_fenics.geometry.FEniCSContinuous(H_DG)\n",
    "#A.domain_geometry = updated_domain_geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMPrior class\n",
    "class SMPrior:\n",
    "    def __init__(self, ginv, corrlength, var, mean, covariancetype=None):\n",
    "        self.corrlength = corrlength\n",
    "        self.mean = mean\n",
    "        self.c = 1e-9  # default value\n",
    "        if covariancetype is not None:\n",
    "            self.covariancetype = covariancetype\n",
    "        else:\n",
    "            self.covariancetype = 'Squared Distance'  # default\n",
    "        self.compute_L(ginv, corrlength, var)\n",
    "\n",
    "    def compute_L(self, g, corrlength, var):\n",
    "        ng = g.shape[0]\n",
    "        a = var - self.c\n",
    "        b = np.sqrt(-corrlength**2 / (2 * np.log(0.01)))\n",
    "        Gamma_pr = np.zeros((ng, ng))\n",
    "\n",
    "        for ii in range(ng):\n",
    "            for jj in range(ii, ng):\n",
    "                dist_ij = np.linalg.norm(g[ii, :] - g[jj, :])\n",
    "                if self.covariancetype == 'Squared Distance':\n",
    "                    gamma_ij = a * np.exp(-dist_ij**2 / (2 * b**2))\n",
    "                elif self.covariancetype == 'Ornstein-Uhlenbeck':\n",
    "                    gamma_ij = a * np.exp(-dist_ij / corrlength)\n",
    "                else:\n",
    "                    raise ValueError('Unrecognized prior covariance type')\n",
    "                if ii == jj:\n",
    "                    gamma_ij = gamma_ij + self.c\n",
    "                Gamma_pr[ii, jj] = gamma_ij\n",
    "                Gamma_pr[jj, ii] = gamma_ij\n",
    "        \n",
    "        self.cov = Gamma_pr\n",
    "        self.L = np.linalg.cholesky(np.linalg.inv(Gamma_pr)).T\n",
    "\n",
    "    def draw_samples(self, nsamples):\n",
    "        samples = self.mean + np.linalg.solve(self.L, np.random.randn(self.L.shape[0], nsamples))\n",
    "        return samples\n",
    "\n",
    "    def eval_fun(self, args):\n",
    "        sigma = args[0]\n",
    "        res = 0.5 * np.linalg.norm(self.L @ (sigma - self.mean))**2\n",
    "        return res\n",
    "    \n",
    "    def evaluate_target_external(self, x, compute_grad=False):\n",
    "        x = x.reshape((-1,1))\n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        # print(\"self.mean.shape: \", self.mean.shape)\n",
    "        if compute_grad:\n",
    "            grad = self.L.T @ self.L @ (x - self.mean)\n",
    "        else:\n",
    "            grad = None\n",
    "        \n",
    "        return self.eval_fun(x), grad\n",
    "        \n",
    "\n",
    "    def compute_hess_and_grad(self, args, nparam):\n",
    "        sigma = args[0]\n",
    "        Hess = self.L.T @ self.L\n",
    "        grad = Hess @ (sigma - self.mean)\n",
    "\n",
    "        if nparam > len(sigma):\n",
    "            Hess = np.block([[Hess, np.zeros((len(sigma), nparam - len(sigma)))],\n",
    "                             [np.zeros((nparam - len(sigma), len(sigma))), np.zeros((nparam - len(sigma), nparam - len(sigma)))]])\n",
    "            grad = np.concatenate([grad, np.zeros(nparam - len(sigma))])\n",
    "\n",
    "\n",
    "        return Hess, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class MyTV:\n",
    "#    def __init__(self, q0fun, mesh, delta,**kwargs):\n",
    "#        #self.qfun = project(qFunction(phi,q1,q2),V1)\n",
    "#\n",
    "#        self.V1 = FunctionSpace(mesh,'CG',1)\n",
    "#        self.V02 = VectorFunctionSpace(mesh,'DG',0)\n",
    "#\n",
    "#        self.q0fun = q0fun\n",
    "#        self.q0grad = project(grad(self.q0fun),self.V02)\n",
    "#        self.q0_denom = Denom(self.q0grad,delta)\n",
    "#\n",
    "#        # operator\n",
    "#        self.p_trial = TrialFunction(self.V1)\n",
    "#        self.p_test = TestFunction(self.V1)\n",
    "#\n",
    "#        #self.L_op = assemble(ufl.inner(self.p_trial, self.p_test)*dx)\n",
    "#        #self.TV_op = assemble(self.q_denom*ufl.inner(grad(self.p_trial),grad(self.p_test))*dx)\n",
    "#        self.TV_op = assemble((self.q0_denom*inner(grad(self.p_trial),grad(self.p_test)))*dx)\n",
    "#\n",
    "#        self.delta = delta\n",
    "#\n",
    "#    def eval_TV(self,qfun):\n",
    "#        self.update_op(qfun)\n",
    "#        return np.dot(self.TV_op * qfun.vector(),qfun.vector())\n",
    "#\n",
    "#    def eval_grad(self,qfun):\n",
    "#        self.update_op(qfun)\n",
    "#        return 2*(self.TV_op * qfun.vector())#[idx2]\n",
    "#    \n",
    "#    def update_op(self,q0fun):\n",
    "#        self.q0fun = q0fun\n",
    "#        self.q0grad = project(grad(self.q0fun),self.V02)\n",
    "#        self.q0_denom = Denom(self.q0grad,self.delta)\n",
    "#        self.TV_op = assemble((self.q0_denom*inner(grad(self.p_trial),grad(self.p_test)))*dx) \n",
    "#\n",
    "\n",
    "class TV_reg:\n",
    "    def __init__(self, V, beta, weight):\n",
    "        self.beta    = dl.Constant(beta)\n",
    "        self.m_tilde  = dl.TestFunction(V)\n",
    "        self.m_hat = dl.TrialFunction(V)\n",
    "        self.weight = weight\n",
    "        \n",
    "    def cost_reg(self, m):\n",
    "        return -self.weight*dl.assemble(dl.sqrt( dl.inner(dl.grad(m), dl.grad(m)) + self.beta)*dl.dx)\n",
    "\n",
    "    \n",
    "    def grad_reg(self, m):  \n",
    "        #print(\"grad\", dl.grad)      \n",
    "        TVm = dl.sqrt( dl.inner(dl.grad(m), dl.grad(m)) + self.beta)\n",
    "        self.TVm = TVm\n",
    "        grad_val = dl.assemble(dl.Constant(1.)/TVm*dl.inner(dl.grad(m), dl.grad(self.m_tilde))*dl.dx)\n",
    "        return -self.weight*grad_val\n",
    "    \n",
    "    def eval_density(self, x):\n",
    "        # convert from numpy array to dolfin function\n",
    "        x_fun = dl.Function(H)\n",
    "        x_fun.vector()[:] = x\n",
    "        return self.cost_reg(x_fun)\n",
    "    \n",
    "    def eval_grad_density(self, x):\n",
    "        # convert from numpy array to dolfin function\n",
    "        x_fun = dl.Function(H)\n",
    "        x_fun.vector()[:] = x\n",
    "        grad_val = self.grad_reg(x_fun).get_local()\n",
    "        return grad_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'diffusion' or model_type == 'diffusion_2D':\n",
    "    H = G_domain.function_space\n",
    "    mesh = H.mesh()\n",
    "elif model_type == 'identity' or model_type == 'convolution':\n",
    "    mesh = dl.UnitIntervalMesh(domain_dim-1)\n",
    "    H = dl.FunctionSpace(mesh, 'CG', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_reg = TV_reg(H, beta=TV_beta, weight=TV_weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'diffusion':\n",
    "    if prior_type == 'Gaussian':\n",
    "        x_true = x.sample()\n",
    "    elif prior_type == 'TV' or prior_type == 'TV_denoiser': \n",
    "        if signal_type == 'step':\n",
    "            fun_x_true_expr = dl.Expression('x[0] > 5 ? 0 : -0.5', degree=1)\n",
    "\n",
    "        elif signal_type == 'square':\n",
    "            fun_x_true_expr = dl.Expression('(x[0]>3.5 && x[0]< 6.5) ? 0 : -0.5', degree=1)\n",
    "\n",
    "        x_true_fun = dl.interpolate(fun_x_true_expr, H)\n",
    "        x_true = cuqi.array.CUQIarray(x_true_fun.vector().get_local(), geometry=A.domain_geometry)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Unrecognized prior type')\n",
    "    \n",
    "elif model_type == 'identity' or model_type == 'convolution':\n",
    "    x_true = cuqi.array.CUQIarray(np.zeros(G_domain.par_dim), geometry=A.domain_geometry)\n",
    "    x_true[G_domain.par_dim//2:] = 1 + np.random.randn(G_domain.par_dim//2)*0.1\n",
    "\n",
    "elif model_type == 'diffusion_2D':\n",
    "    # set a 2D signal with a square in the middle\n",
    "    fun_x_true_expr = dl.Expression('(x[0]>0.35 && x[0]< 0.65 && x[1]>0.35 && x[1]< 0.65) ? 0 : -0.5', degree=1)\n",
    "    x_true_fun = dl.interpolate(fun_x_true_expr, H)\n",
    "    x_true = cuqi.array.CUQIarray(x_true_fun.vector().get_local(), geometry=A.domain_geometry)\n",
    "\n",
    "\n",
    "\n",
    "im = x_true.plot()\n",
    "if physical_dim == 2:\n",
    "    plt.colorbar(im[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell to compute s_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_true.shape\n",
    "y_true = A(x_true)\n",
    "s_noise = 1.0/np.sqrt(G_domain.par_dim)* noise_level*np.linalg.norm(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl.plot(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mesh.num_cells()/2)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prior_type == 'Gaussian':\n",
    "    cov_const = 1 #100\n",
    "    x = Gaussian(np.zeros(G_domain.par_dim), cov=cov_const*smprior.cov, geometry=G_domain)\n",
    "elif prior_type == 'TV':\n",
    "    # CUQIpy user defined distribution\n",
    "    x = cuqi.distribution.UserDefinedDistribution(logpdf_func=tv_reg.eval_density,\n",
    "                                              gradient_func=tv_reg.eval_grad_density,\n",
    "                                              dim=H.dim())\n",
    "elif prior_type == 'TV_denoiser':\n",
    "    \n",
    "    \n",
    "    restoration_strength = restoration_strength_factor  * s_noise**2\n",
    "    \n",
    "    \n",
    "    if physical_dim == 1:\n",
    "        def prox_g(x, restoration_strength=None):\n",
    "            return denoise_tv_chambolle(x, weight=restoration_strength, max_num_iter=100), None\n",
    "    elif physical_dim == 2:\n",
    "        def prox_g(x, restoration_strength=None):\n",
    "            # x is dof of the function, create a function from the dof\n",
    "            H_prox = A.domain_geometry.function_space\n",
    "            x_fun = dl.Function(H_prox)\n",
    "            x_fun.vector()[:] = x\n",
    "            # convert to numpy array on a 2D grid\n",
    "            vertices_on_axis = int(np.sqrt(A.domain_geometry.mesh.num_vertices()))\n",
    "            x_grid = x_fun.compute_vertex_values().reshape((vertices_on_axis,vertices_on_axis)) \n",
    "            denoised_image = denoise_tv_chambolle(x_grid, weight=restoration_strength, max_num_iter=100)\n",
    "            \n",
    "            # reorder denoised image to dof\n",
    "            # TODO: we can call dl.dof_to_vertex_map once only for performance\n",
    "            d2v = dl.dof_to_vertex_map(A.domain_geometry.function_space)\n",
    "            return  denoised_image.flatten()[d2v], None   \n",
    "    \n",
    "    \n",
    "    # %%\n",
    "    # We save all the important variables into the variable\n",
    "    # :math:`\\texttt{restorator_kwargs}`.\n",
    "\n",
    "    # %%\n",
    "    # Now we can define our RestorationPrior.\n",
    "    restorator = RestorationPrior(\n",
    "        prox_g,\n",
    "        geometry=A.domain_geometry\n",
    "    )\n",
    "    x = MoreauYoshidaPrior(restorator, smoothing_strength=restoration_strength)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Gaussian(A(x), s_noise**2, geometry=G_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = y(x=x_true).sample()\n",
    "y_obs.plot()\n",
    "y_true.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.logpdf(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_1 = np.random.randn(G_domain.par_dim)\n",
    "# x_1 step function\n",
    "x_1 = np.zeros(G_domain.par_dim)\n",
    "x_1[G_domain.par_dim//2:] = 1\n",
    "x_1_cuqiarray = cuqi.array.CUQIarray(x_1)\n",
    "x_1_cuqiarray.plot()\n",
    "plt.figure()\n",
    "# verify the TV gradient computation\n",
    "try:\n",
    "    plt.plot(x.gradient(x_1))\n",
    "except:\n",
    "    pass\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(x.logd, x_1, 1e-12), '--')\n",
    "plt.legend(['TV class', 'finite difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_prior:\n",
    "    # sample the prior \n",
    "    Ns_prior = 1\n",
    "    if prior_type == 'Gaussian':\n",
    "        x_samples = x.sample(Ns_prior)\n",
    "    \n",
    "    elif prior_type == 'TV':\n",
    "        prior_sampler = NUTS(x, max_depth=5)\n",
    "        prior_sampler.warmup(1)\n",
    "        prior_sampler.sample(Ns_prior)\n",
    "        x_samples = prior_sampler.get_samples()\n",
    "    \n",
    "    #x_samples.plot()\n",
    "    \n",
    "    x_samples.plot_trace()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_prior:\n",
    "    x_samples.compute_ess()\n",
    "    #x_samples.burnthin(5).plot_ci()\n",
    "    plt.figure()\n",
    "    x_samples.plot([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = BayesianProblem(y, x).set_data(y=y_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_1, label='x_1')\n",
    "\n",
    "x_2 = np.random.randn(G_domain.par_dim)\n",
    "plt.plot(x_2, label='x_2')\n",
    "plt.legend()\n",
    "#print(x.logd(x_1))\n",
    "#print(x.logd(x_1*0+1))\n",
    "#print(x.logd(np.random.randn(G_domain.par_dim)))\n",
    "\n",
    "# at x_1 , logd for prior and for likelihood\n",
    "print('x.logd(x_1)', x.logd(x_1))\n",
    "print('BP.likelihood.logd(x_1)', BP.likelihood.logd(x_1))\n",
    "\n",
    "# at x_1 , logd for prior and for likelihood\n",
    "print('x.logd(0.5*x_1)', x.logd(x_1*0.5))\n",
    "print('BP.likelihood.logd(0.5*x_1)', BP.likelihood.logd(x_1*0.5))\n",
    "\n",
    "# at x_2 , logd for prior and for likelihood\n",
    "print('x.logd(x_2)', x.logd(x_2))\n",
    "print('BP.likelihood.logd(x_2)', BP.likelihood.logd(x_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map point\n",
    "if enable_FD:\n",
    "    BP.posterior.enable_FD() \n",
    "else:\n",
    "    BP.posterior.disable_FD()\n",
    "map_x = BP.MAP()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot map predicted data\n",
    "\n",
    "y_obs.plot(label='y_obs')\n",
    "\n",
    "if prior_type != 'TV_denoiser':\n",
    "    plt.figure()\n",
    "    A(map_x).plot(label='A(x_map)')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot of two columns and one row\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plt.sca(axs[0])\n",
    "\n",
    "if physical_dim == 2:\n",
    "    im = map_x.plot(subplots=False, vmin=-0.6, vmax=0.1, mode='color')\n",
    "    # min value of the colorbar is set to -1.0\n",
    "    plt.colorbar(im[0])#, ticks=range(-1, 0, 5))\n",
    "else:\n",
    "    im = map_x.plot(subplots=False)\n",
    "\n",
    "plt.sca(axs[1])\n",
    "\n",
    "\n",
    "\n",
    "if physical_dim == 2:\n",
    "    im = x_true.plot(subplots=False, vmin=-0.6, vmax=0.1, mode='color')\n",
    "    plt.colorbar(im[0])\n",
    "else:\n",
    "    im = x_true.plot(subplots=False)\n",
    "    plt.ylim(-1.0, 0.7)\n",
    "    plt.legend(['MAP', 'True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_x0_map_tobe_true:\n",
    "    x0_map = x_true\n",
    "else:\n",
    "    x0_map = x_true*0+0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_map.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy solver BFGS\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "fmin_bfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_bfgs\n",
    "if run_scipy_with_callback:\n",
    "    Nfeval = 1\n",
    "    \n",
    "    \n",
    "    def callbackF(Xi):\n",
    "        global Nfeval\n",
    "        # plot Xi every 10 iterations\n",
    "        if Nfeval % 10 == 0:\n",
    "            plt.plot(Xi)\n",
    "            # print function value and gradient norm\n",
    "            print(\"{0:4d}   {1: 3.6f}   {2: 3.6f}   \".format(Nfeval, \n",
    "                                                            (-BP.posterior.logd(Xi)).to_numpy()[0],\n",
    "                                                            np.linalg.norm(- BP.posterior.gradient(Xi))))\n",
    "            \n",
    "    \n",
    "           #print(\"{0:4d}   {1: 3.6f}   {2: 3.6f}   {3: 3.6f}   {4: 3.6f}\".format(Nfeval, Xi[0], Xi[1], Xi[2], rosen(Xi)))\n",
    "        \n",
    "        #print(\"{0:4d}   {1: 3.6f}   {2: 3.6f}   {3: 3.6f}   {4: 3.6f}\".format(Nfeval, Xi[0], Xi[1], Xi[2], rosen(Xi)))\n",
    "        Nfeval += 1\n",
    "    \n",
    "    print('{0:4s}   {1:9s}   {2:9s}   {3:9s}   {4:9s}'.format('Iter', ' X1', ' X2', ' X3', 'f(X)')  ) \n",
    "    x0 = np.array([1.1, 1.1, 1.1], dtype=np.double)\n",
    "    [xopt, fopt, gopt, Bopt, func_calls, grad_calls, warnflg] = \\\n",
    "        fmin_bfgs(lambda x: -BP.posterior.logd(x),\n",
    "                  x0_map*0,\n",
    "                  #fprime=lambda x : -BP.posterior.gradient(x), \n",
    "                  callback=callbackF, \n",
    "                  disp=1,\n",
    "                  maxiter=2000, \n",
    "                  full_output=True, \n",
    "                  retall=False,\n",
    "                  gtol=5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(xopt)\n",
    "#plt.plot(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(xopt)\n",
    "#plt.plot(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(xopt, fopt, gopt, Bopt, func_calls, grad_calls, warnflg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TV_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35, 1e-7\n",
    "if apply_grid_search:\n",
    "    # grid search for computing the map\n",
    "    grid_weights = [60, 90, 120]\n",
    "    grid_beta = [1e-6, 1e-9] #1e-3, 1e-4, \n",
    "    map_list = []\n",
    "    weight_list = []\n",
    "    beta_list = []\n",
    "    TV_m_list = []\n",
    "    \n",
    "    for i, weight in enumerate(grid_weights):\n",
    "        for j, beta in enumerate(grid_beta):\n",
    "            print('iteration number {} of total {}'.format(i*len(grid_beta) + j, len(grid_weights)*len(grid_beta)))\n",
    "            print('weight: ', weight)\n",
    "            print('beta: ', beta)\n",
    "            TV_reg_i = TV_reg(H, beta=beta, weight=weight)\n",
    "            # define x\n",
    "            x = cuqi.distribution.UserDefinedDistribution(logpdf_func=TV_reg_i.eval_density,\n",
    "                                                        gradient_func=TV_reg_i.eval_grad_density,\n",
    "                                                        dim=H.dim())\n",
    "            BP_i = BayesianProblem(y, x).set_data(y=y_obs)\n",
    "            BP_i.posterior.disable_FD()\n",
    "            map_x = BP_i.MAP(x0=x0_map)\n",
    "            TV_m_list.append(TV_reg_i.TVm)\n",
    "            map_list.append(map_x)\n",
    "            weight_list.append(weight)\n",
    "            beta_list.append(beta)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_grid_search:\n",
    "    if physical_dim == 1:\n",
    "        # plot all map points with labels\n",
    "        style = ['-', '--', '-.', ':']*3\n",
    "        starting_idx = 0\n",
    "        for i, map_x_i in enumerate(map_list[starting_idx:starting_idx+3]):\n",
    "            map_x_i.plot(label='weight: '+str(weight_list[starting_idx+i])+' beta: '+str(beta_list[starting_idx+i]) + ' TVm: '+str(dl.assemble(TV_m_list[starting_idx+i]*dl.dx)), linestyle=style[i])\n",
    "            # print(map_x_i.info)\n",
    "        \n",
    "        x_true.plot(label='True', color='black')\n",
    "        plt.ylim(-0.6, 0.1)\n",
    "        #plot f\n",
    "\n",
    "        plt.plot(x_grid, f(x_grid)-0.5)\n",
    "\n",
    "        # plot legend and put it outside the plot\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    elif physical_dim == 2:\n",
    "\n",
    "        # create a subplot of two columns and one row\n",
    "        fig, axs = plt.subplots(len(grid_weights), len(grid_beta), figsize=(15, 15))\n",
    "        for i in range(len(grid_weights)):\n",
    "            for j in range(len(grid_beta)):\n",
    "                plt.sca(axs[i, j])\n",
    "                im = map_list[i*len(grid_beta) + j].plot(subplots=False, vmin=-0.6, vmax=0.1, mode='color')\n",
    "                plt.title('weight: '+str(weight_list[i*len(grid_beta) + j])+' beta: '+str(beta_list[i*len(grid_beta) + j]) + ' TVm: '+str(dl.assemble(TV_m_list[i*len(grid_beta) + j]*dl.dx)))\n",
    "                plt.colorbar(im[0])\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Unrecognized physical dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x0_map.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_x.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior_samples = BP.UQ(Ns=3000, Nb=2, percent=97)\n",
    "posterior = BP.posterior()\n",
    "#sampler = cuqi.sampler.NUTS(posterior, max_depth=4, x0=np.zeros(G_domain.par_dim)+.001)\n",
    "#sampler = cuqi.sampler.ULA(posterior, x0=np.zeros(G_domain.par_dim)+.001, scale=0.00000005)\n",
    "# np.zeros(G_domain.par_dim)+.001\n",
    "\n",
    "#initial_point = np.zeros(G_domain.par_dim) # x_true.to_numpy()\n",
    "#initial_point = 0.5*map_x.to_numpy()\n",
    "#initial_point = map_x.to_numpy()\n",
    "initial_point = np.ones(G_domain.par_dim)*-0.25\n",
    "\n",
    "#sampler = cuqi.experimental.mcmc.PCN(posterior, initial_point=initial_point, scale=0.05)#, max_depth=10, scale=0.005)\n",
    "\n",
    "if sampler_choice == \"NUTS\":\n",
    "    sampler = cuqi.experimental.mcmc.NUTS(posterior,\n",
    "                                          initial_point=initial_point,\n",
    "                                          max_depth=max_depth,\n",
    "                                          step_size=step_size)\n",
    "\n",
    "elif sampler_choice == \"MALA\":\n",
    "    sampler = cuqi.experimental.mcmc.MALA(posterior, initial_point=initial_point, scale=2.1e-7)\n",
    "    Ns = 1000\n",
    "    Nb = 20\n",
    "\n",
    "elif sampler_choice == \"ULA\":\n",
    "    sampler = cuqi.experimental.mcmc.ULA(posterior, initial_point=initial_point, scale=2.1e-7)\n",
    "\n",
    "\n",
    "elif sampler_choice == \"MH\":\n",
    "    sampler = cuqi.experimental.mcmc.MH(posterior, initial_point=initial_point, scale=2.1e-5)\n",
    "    Ns = 1000\n",
    "    Nb = 20\n",
    "\n",
    "elif sampler_choice == \"myULA\":\n",
    "    \n",
    "    sampler = ULA(posterior, scale=1e-4, initial_point=initial_point)\n",
    "\n",
    "_ = sampler.warmup(Nb)\n",
    "all_samples_list = []\n",
    "all_samples_list.append(sampler.get_samples().samples)\n",
    "sampler._samples = []\n",
    "if sample_batches:\n",
    "    N_batches = 10\n",
    "    for batch_idx in range(N_batches):\n",
    "        print(f'batch number {batch_idx} of {N_batches}')\n",
    "        _ = sampler.sample(int(Ns/N_batches))\n",
    "        samples_batch = sampler.get_samples()\n",
    "        all_samples_list.append(samples_batch.burnthin(Nb=0, Nt=Nt).samples)\n",
    "        #sampler.save_checkpoint('checkpoint_'+expr_tag+'.pickle')\n",
    "        #sampler.reset()\n",
    "        #sampler.load_checkpoint('checkpoint_'+expr_tag+'.pickle')\n",
    "        sampler._samples = []\n",
    "\n",
    "    all_samples_array = np.concatenate(all_samples_list, axis=1) #TODO 0 or 1\n",
    "    posterior_samples_pre = cuqi.samples.Samples(all_samples_array, geometry=A.domain_geometry)    \n",
    "    \n",
    "\n",
    "\n",
    "else:\n",
    "    _ = sampler.sample(Ns)\n",
    "    posterior_samples_pre = sampler.get_samples()\n",
    "\n",
    "\n",
    "#posterior_samples = sampler.sample_adapt(100, Nb=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_samples_array = np.concatenate(all_samples_list, axis=1)\n",
    "#posterior_samples_pre = cuqi.samples.Samples(all_samples_array, geometry=A.domain_geometry) \n",
    "#print(all_samples_array.shape)\n",
    "#print(17*17)\n",
    "#print(Ns)\n",
    "#print(Nb)\n",
    "#print(Nt)\n",
    "#type(posterior_samples_pre.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_burnin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = posterior_samples_pre.burnthin(remove_burnin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(sampler.scale)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.plot(sampler.num_tree_node_list)\n",
    "    plt.figure()\n",
    "    plt.semilogy(sampler.epsilon_list)\n",
    "    plt.semilogy(sampler.epsilon_bar_list)\n",
    "    print(np.max(sampler.epsilon_list))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler.scale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code cell for generating Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_type == 'diffusion' or model_type == 'diffusion_2D':\n",
    "\n",
    "    import os\n",
    "    from matplotlib import ticker\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set up matplotlib\n",
    "    SMALL_SIZE = 7\n",
    "    MEDIUM_SIZE = 8\n",
    "    BIGGER_SIZE = 9\n",
    "    plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    # Use latex package\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "    \n",
    "    # Data directory\n",
    "    fig_dir = './figs/'\n",
    "    \n",
    "    # Figure file\n",
    "    fig_dir = fig_dir \n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(fig_dir):\n",
    "        os.makedirs(fig_dir)\n",
    "    \n",
    "    # Figure version\n",
    "    version = 'v8'\n",
    "    \n",
    "    # Figure file\n",
    "    fig_file = fig_dir + 'paper_figure1_'+expr_tag+'_'+version+'.pdf'\n",
    "    \n",
    "    # Create the figure\n",
    "    cm_to_in = 1/2.54\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=3,\n",
    "                            figsize=(17.8*cm_to_in, 9.8*cm_to_in),\n",
    "                            layout=\"constrained\")\n",
    "    \n",
    "    # Define the colors to be used in the plots\n",
    "    colors = ['C0', 'green', 'purple', 'k', 'gray']\n",
    "    \n",
    "    # (a)\n",
    "    plt.sca(axs[0,0])\n",
    "    \n",
    "    \n",
    "    if physical_dim == 2: \n",
    "        im = x_true.plot(subplots=False, vmin=-0.55, vmax=0.02, mode='color')\n",
    "        inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "        fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "        plt.gca().set_ylim(0, 1)\n",
    "    else:\n",
    "        im = x_true.plot(subplots=False)\n",
    "    \n",
    "    #plt.gca().set_xlim(0, 1)\n",
    "    plt.gca().set_title('(a) Exact solution')\n",
    "    plt.ylabel('$\\\\xi^2$')\n",
    "    plt.gca().yaxis.labelpad = -5\n",
    "    plt.xlabel('$\\\\xi^1$')\n",
    "    plt.gca().xaxis.labelpad = -5\n",
    "    \n",
    "    # (b)\n",
    "    plt.sca(axs[0,1])\n",
    "    im = y_true.plot(subplots=False)\n",
    "    \n",
    "    if physical_dim == 2:\n",
    "        inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "        fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "        plt.ylabel('$\\\\xi^2$')\n",
    "        plt.gca().yaxis.labelpad = -5\n",
    "        plt.gca().set_title('(b) Exact data')\n",
    "    else:\n",
    "        samples_mean = cuqi.array.CUQIarray(posterior_samples.mean(), geometry=G_domain)\n",
    "        A(samples_mean).plot(subplots=False)\n",
    "        plt.gca().set_title('(b) Exact and predicted data')\n",
    "    plt.xlabel('$\\\\xi^1$')\n",
    "    plt.gca().xaxis.labelpad = -5\n",
    "    \n",
    "    \n",
    "    # (c)\n",
    "    plt.sca(axs[0,2])\n",
    "    im = y_obs.plot(subplots=False)\n",
    "    if physical_dim == 2:\n",
    "        inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "        fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "        plt.ylabel('$\\\\xi^2$')\n",
    "        plt.gca().yaxis.labelpad = -5\n",
    "    plt.xlabel('$\\\\xi^1$')\n",
    "    plt.gca().xaxis.labelpad = -5\n",
    "    plt.gca().set_title('(c) Noisy data')\n",
    "    \n",
    "    # (d)\n",
    "    plt.sca(axs[1,0])\n",
    "\n",
    "    if physical_dim == 2:\n",
    "        im = posterior_samples.plot_mean(\n",
    "            subplots=False, vmin=-0.55, vmax=0.02, mode='color')\n",
    "        inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "        fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "        plt.gca().set_ylim(0, 1)\n",
    "        plt.ylabel('$\\\\xi^2$')\n",
    "        plt.gca().yaxis.labelpad = -5\n",
    "    else:\n",
    "        im = posterior_samples.plot_mean(subplots=False)\n",
    "    \n",
    "    #plt.gca().set_xlim(0, 1)\n",
    "    plt.xlabel('$\\\\xi^1$')\n",
    "    plt.gca().xaxis.labelpad = -5\n",
    "    plt.gca().set_title('(d) Posterior mean')\n",
    "    \n",
    "    # (e)\n",
    "    plt.sca(axs[1,1])\n",
    "    im = posterior_samples.funvals.vector.plot_std(subplots=False)\n",
    "    \n",
    "    if physical_dim == 2:\n",
    "        inset_axes = plt.gca().inset_axes([1.04, 0.2, 0.05, 0.6])\n",
    "        cb = fig.colorbar(im[0], ax=plt.gca(), cax=inset_axes)\n",
    "        cb.locator = ticker.MaxNLocator(nbins=4)\n",
    "        plt.ylabel('$\\\\xi^2$')\n",
    "        plt.gca().yaxis.labelpad = -5\n",
    "    plt.xlabel('$\\\\xi^1$')\n",
    "    plt.gca().xaxis.labelpad = -5\n",
    "    plt.gca().set_title('(e) Posterior STD')\n",
    "    \n",
    "    # (f)\n",
    "    plt.sca(axs[1,2])\n",
    "    lci = posterior_samples.plot_ci(\n",
    "        97, exact=x_true, plot_par=True, markersize=SMALL_SIZE-3)\n",
    "    lci[0].set_label(\"Mean\")\n",
    "    lci[1].set_label(\"Exact\")\n",
    "    lci[2].set_label(\"$97\\\\%$ CI\")\n",
    "    #plt.ylim(-5, 3)\n",
    "    plt.legend(ncols=2) \n",
    "    plt.ylabel(r'$\\bm{x}_i$')\n",
    "    plt.gca().yaxis.labelpad = -5\n",
    "    plt.gca().yaxis.set_label_coords( -0.06, 0.5)\n",
    "    plt.xlabel('$i$')\n",
    "    plt.gca().xaxis.labelpad = -5\n",
    "    plt.gca().set_title('(f) Posterior CI')\n",
    "    n_ticks = 8\n",
    "    num_var = posterior_samples.geometry.par_dim\n",
    "    tick_ids = np.linspace(0, num_var-1, n_ticks, dtype=int)\n",
    "    plt.xticks(tick_ids, tick_ids)\n",
    "    # switch legend off\n",
    "    plt.gca().legend().set_visible(False)\n",
    "\n",
    "    ess_list = posterior_samples.compute_ess()\n",
    "    plt.suptitle(expr_tag+' ESS: '+str(np.min(ess_list))+', '+str(np.max(ess_list))+', '+str(np.mean(ess_list)))\n",
    "    # Save the figure\n",
    "    plt.savefig(fig_file, bbox_inches='tight', pad_inches=0.01, dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from exact solution extract indices of the square\n",
    "if model_type == 'diffusion_2D':\n",
    "    indices_of_square = np.where(x_true.to_numpy() > -0.2)[0]\n",
    "\n",
    "reordered_samples = np.zeros_like(posterior_samples.samples)\n",
    "reordered_samples[ :len(indices_of_square), :] = posterior_samples.samples[ indices_of_square, :]\n",
    "reordered_samples[ len(indices_of_square):, :] = posterior_samples.samples[ np.setdiff1d(np.arange(G_domain.par_dim), indices_of_square), :]\n",
    "\n",
    "reordered_CUQI_samples = cuqi.samples.Samples(reordered_samples)\n",
    "\n",
    "reordered_CUQI_samples.plot_ci()\n",
    "plt.plot(np.ones(G_domain.par_dim)*-0.5, '--')\n",
    "plt.plot(np.ones(G_domain.par_dim)*0, '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run for multiple cases:\n",
    "\n",
    "mesh = 16 by 16, 32 by 32, 64 by 64 (3 options)\n",
    "TV_weight = 10, 20, 30 (3 options)\n",
    "smoothing_factor = 0.005, 0.01, 0.02 (3 options)\n",
    "number of samples = 2000 * 25 (1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(ess_list)\n",
    "print(np.min(ess_list))\n",
    "print(np.max(ess_list))\n",
    "print(np.mean(ess_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot([-1, -3, -5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "posterior_samples.plot_ci(exact=x_true, plot_par=plot_par)\n",
    "plt.title('Posterior CI (with burnin)')\n",
    "plt.figure()\n",
    "posterior_samples_pre.plot_ci(exact=x_true, plot_par=plot_par)\n",
    "plt.title('Posterior CI (without burnin)')\n",
    "plt.figure()\n",
    "mapped_samples = cuqi.samples.Samples( np.exp(posterior_samples.samples))\n",
    "mapped_samples.plot_ci()\n",
    "plt.figure()\n",
    "mapped_samples.plot()\n",
    "\n",
    "plt.figure()\n",
    "samples_geom2 = cuqi.samples.Samples( posterior_samples.samples)\n",
    "samples_geom2.plot_ci()\n",
    "plt.figure()\n",
    "samples_geom2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [x] 1D case \n",
    "# - [ ] DG0\n",
    "# - [ ] TV with non-MY gradient and with NUTS \n",
    "# - [x] verify the gradient of the posterior\n",
    "# - [x] PCN seems to work (for both 1D and 2D cases)\n",
    "# - [x] Start from x0=the true parameter to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify gradient  (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(3)\n",
    "# random direction y\n",
    "y0 = np.ones(G_range.par_dim) # np.random.randn(G_range.par_dim)\n",
    "y0[0] = 0\n",
    "y0[-1] = 0\n",
    "\n",
    "# corresponding fenics function\n",
    "y0_fun = dl.Function(H)\n",
    "y0_fun.vector()[:] = y0\n",
    "\n",
    "# objective function\n",
    "def f(x):\n",
    "    return A(x).T@ y0.reshape(-1,1)\n",
    "    #return A(x).vector().get_local().T@ y0.reshape(-1,1)\n",
    "\n",
    "# objective function gradient\n",
    "def fprime(x):\n",
    "    return A.gradient(y0, x)\n",
    "\n",
    "# random input x (the point which gradient is calculated with respect to)\n",
    "x0 = np.random.randn(G_domain.par_dim)\n",
    "\n",
    "# assert that the gradient is correct\n",
    "print(check_grad(f, fprime, x0))\n",
    "\n",
    "plt.plot(fprime(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(f, x_true, 1e-6), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify gradient  (posterior)\n",
    "\n",
    "plt.plot(posterior.gradient(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(posterior.logd, x_true, 1e-8), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the gradient of the prior\n",
    "\n",
    "plt.plot(x.gradient(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(x.logd, x_true, 1e-8), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the gradient of the likelihood\n",
    "\n",
    "plt.plot(posterior.likelihood.gradient(x_true))\n",
    "# plot finite difference gradient \n",
    "\n",
    "plt.plot(approx_gradient(posterior.likelihood.logd, x_true, 1e-10), '--')\n",
    "plt.legend(['adjoint based', 'finite difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save samples\n",
    "#thinned_samples = posterior_samples.burnthin(Nb=0, Nt=20)\n",
    "np.savez('posterior_samples_2D'+expr_tag+'.npz',\n",
    "         samples=posterior_samples.samples, data = y_obs.to_numpy(), x_true=x_true.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 3,
  "vscode": {
   "interpreter": {
    "hash": "f83c72a7c5d885a4a7f43561cb77434137f6f5cf21a7418d4732e18616218db3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
